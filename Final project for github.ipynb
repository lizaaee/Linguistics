{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33630622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18170da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/lisa/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/lisa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk import download\n",
    "download('punkt_tab')\n",
    "download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('russian')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e5686",
   "metadata": {},
   "source": [
    "Первый этап — извлечение всех сообщений из Telegram-канала:\n",
    "-парсинг Telegram-канала по частям, так как объём очень большой (сентябрь–апрель 2022–2023, сентябрь–апрель 2023–2024, сентябрь–апрель 2024–2025, август–январь 2025–2026)\n",
    "-применяем BeautifulSoup к каждому документу\n",
    "-извлекаем текст из каждого сообщения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3f5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#прописываем функцию для получения супа из html-файла с сообщениями (в данном случае - из файла с сообщениями из телеграм-канала)\n",
    "def soup_for_messages(filename, encoding=\"utf-8\"):\n",
    "    with codecs.open(filename, \"r\", encoding) as f:\n",
    "        html_content = f.read()\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76cb2d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#прописываем функцию для экстракции текста сообщения \n",
    "def extract_messages(soup):\n",
    "    stop_phrases = [ \"добро пожаловать в чат нови сада\", \"я не робот\", \"userinfo|bot\", \"кикнут\", \"разбаном в настройках чата\" ]\n",
    "    messages = []\n",
    "    for i in soup.find_all('div', {'class': \"body\"}):\n",
    "        text_div = i.find('div', {'class': \"text\"})\n",
    "        if text_div is not None:\n",
    "            res = text_div.text.strip().replace('\\n', ' ').lower()\n",
    "            if any(phrase in res for phrase in stop_phrases): \n",
    "                continue\n",
    "            messages.append(res)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee78e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages_2022 = []\n",
    "soup = soup_for_messages(\"/Users/lisa/Desktop/Linguistics/Проект/сентябрь 22 - апрель 23/messages.html\")\n",
    "all_messages_2022.extend(extract_messages(soup))\n",
    "\n",
    "for i in range(2, 55):\n",
    "    file_path = f\"/Users/lisa/Desktop/Linguistics/Проект/сентябрь 22 - апрель 23/messages{i}.html\"\n",
    "    \n",
    "    soup = soup_for_messages(file_path)\n",
    "    all_messages_2022.extend(extract_messages(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e71cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages_2023 = []\n",
    "soup = soup_for_messages(\"/Users/lisa/Desktop/Linguistics/Проект/сентябрь 2023 - апрель 2024 /messages.html\")\n",
    "all_messages_2023.extend(extract_messages(soup))\n",
    "\n",
    "for i in range(2, 77):\n",
    "    file_path = f\"/Users/lisa/Desktop/Linguistics/Проект/сентябрь 2023 - апрель 2024 /messages{i}.html\"\n",
    "    \n",
    "    soup = soup_for_messages(file_path)\n",
    "    all_messages_2023.extend(extract_messages(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4407792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages_2024 = []\n",
    "soup = soup_for_messages(\"/Users/lisa/Desktop/Linguistics/Проект/сентябрь 2024 - апрель 2025 /messages.html\")\n",
    "all_messages_2024.extend(extract_messages(soup))\n",
    "\n",
    "for i in range(2, 55):\n",
    "    file_path = f\"/Users/lisa/Desktop/Linguistics/Проект/сентябрь 2024 - апрель 2025 /messages{i}.html\"\n",
    "    \n",
    "    soup = soup_for_messages(file_path)\n",
    "    all_messages_2024.extend(extract_messages(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9738c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages_2025 = []\n",
    "soup = soup_for_messages(\"/Users/lisa/Desktop/Linguistics/Проект/август 2025 - январь 2026/messages.html\")\n",
    "all_messages_2025.extend(extract_messages(soup))\n",
    "\n",
    "for i in range(2, 47):\n",
    "    file_path = f\"/Users/lisa/Desktop/Linguistics/Проект/август 2025 - январь 2026/messages{i}.html\"\n",
    "    \n",
    "    soup = soup_for_messages(file_path)\n",
    "    all_messages_2025.extend(extract_messages(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a39203",
   "metadata": {},
   "source": [
    "На втором этапе проводим очистку сообщений:\n",
    "-создаём список стоп-слов (стандартный список + добавленные)\n",
    "-запускаем функцию, в которой очищаем текст от пунктуации, стоп-слов и слов, отличных от кириллицы\n",
    "-токенизируем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81b250ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')\n",
    "stop_words = stop_words + ['это', 'всё', 'очень', 'то', 'что', 'с','привет','спасибо','просто','ещё','в','почему','такое', 'подскажите', 'пожалуйста','добрый', 'день','напишите','вечер','доброе', 'утро','скажите','день','всем','вообще','вроде', 'общем','кикнут','кик','разбаном','проголосовали', 'т', 'д','нови', 'сад', 'саде', 'сада', 'какие','например','могу', 'сегодня','знаю', 'нужно','пока','кого', 'кто', 'который','вопрос']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56b8447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#прописываем функцию для очистки сообщений от пунктуации, стоп-слов и слов, отличных от кириллицы\n",
    "def clean_messages(messages):\n",
    "    cleaned=[]\n",
    "    messages_without_punk=[word for word in messages if word[0].isalnum()]\n",
    "    messages_cleaned= [word for word in messages_without_punk if word not in stop_words]\n",
    "    russian_words = [w for w in messages_cleaned if re.fullmatch(r\"[А-Яа-яЁё]+\", w)]\n",
    "    cleaned.extend(russian_words)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e3e65d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ребята', 'скиньте', 'номер', 'такси', 'срочно', 'чатика', 'подающих', 'визы', 'сербии', 'кажется']\n"
     ]
    }
   ],
   "source": [
    "#токенизированные и очищенные сообщения по годам\n",
    "text_2022 = \" \".join(all_messages_2022) \n",
    "res_2022 = wordpunct_tokenize(text_2022)\n",
    "messages_cleaned_2022=clean_messages(res_2022)\n",
    "print(messages_cleaned_2022[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb507c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2023 = \" \".join(all_messages_2023) \n",
    "res_2023 = wordpunct_tokenize(text_2023)\n",
    "messages_cleaned_2023=clean_messages(res_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2040cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2024 = \" \".join(all_messages_2024) \n",
    "res_2024 = wordpunct_tokenize(text_2024)\n",
    "messages_cleaned_2024=clean_messages(res_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9fde6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2025 = \" \".join(all_messages_2025) \n",
    "res_2025 = wordpunct_tokenize(text_2025)\n",
    "messages_cleaned_2025=clean_messages(res_2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa131221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#пробуем сделать лемматизацию с помощью станзы, но к сожалению, объем документа слишком большой \n",
    "#%pip install stanza\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import stanza\n",
    "#stanza.download(\"ru\")\n",
    "#nlp_stanza = stanza.Pipeline(lang=\"ru\", processors=\"tokenize, pos, lemma, depparse, ner\")\n",
    "#lemma_2022=nlp_stanza(text_2022)\n",
    "#print(lemma_2022[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37afd5b0",
   "metadata": {},
   "source": [
    "На третьем этапе проводим анализ корпуса:\n",
    "-считаем частотные слова для каждого документа (20 самых частотных слов)\n",
    "-считаем TF-IDF с некоторой поправкой на значимые слова для каждого документа\n",
    "-выводим топ-20 слов для всего корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "723d31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#скачиваем каунтер для подсчета количества \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eacc9cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('сербии', 1408), ('рф', 1327), ('евро', 1164), ('нс', 1012), ('внж', 1001), ('купить', 849), ('время', 743), ('работает', 684), ('найти', 669), ('точно', 659), ('месяц', 644), ('россии', 639), ('сколько', 629), ('знает', 583), ('сразу', 573), ('динар', 565), ('думаю', 563), ('стоит', 562), ('именно', 550), ('деньги', 537)] \n",
      "\n",
      "[('сербии', 1724), ('внж', 1648), ('рф', 1592), ('нс', 1182), ('евро', 1168), ('купить', 1112), ('время', 1003), ('знает', 954), ('работает', 924), ('сколько', 898), ('точно', 814), ('сразу', 813), ('год', 806), ('найти', 801), ('которые', 769), ('могут', 766), ('деньги', 761), ('стоит', 758), ('кстати', 734), ('года', 730)] \n",
      "\n",
      "[('сербии', 1361), ('внж', 1018), ('рф', 967), ('нс', 915), ('евро', 868), ('работает', 808), ('знает', 763), ('время', 758), ('точно', 748), ('года', 714), ('купить', 709), ('которые', 661), ('год', 638), ('могут', 637), ('сколько', 605), ('именно', 582), ('возможно', 581), ('найти', 576), ('чат', 572), ('поэтому', 569)] \n",
      "\n",
      "[('сербии', 983), ('внж', 847), ('рф', 813), ('точно', 640), ('работает', 639), ('евро', 625), ('нс', 603), ('время', 567), ('именно', 542), ('купить', 529), ('могут', 517), ('человек', 513), ('поэтому', 511), ('которые', 507), ('лет', 495), ('хотя', 490), ('знает', 490), ('года', 486), ('кстати', 480), ('сразу', 465)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#смотрим 20 самых частотных слов в каждом году\n",
    "word_freq_for_corpus = [Counter(messages_cleaned_2022).most_common(20), Counter(messages_cleaned_2023).most_common(20), Counter(messages_cleaned_2024).most_common(20), Counter(messages_cleaned_2025).most_common(20)]\n",
    "for result in word_freq_for_corpus:\n",
    "    print(result, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3680ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%pip install scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42f96124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lisa/Library/Python/3.13/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lisa/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b54e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 43044)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#прописываем векторизацию для всего корпуса, объединяя все сообщения в один список\n",
    "#min_df=2 Минимальная частота документа: слово должно встречаться минимум в 2 документах, чтобы попасть в словарь\n",
    "#max_df=0.9 Максимальная частота документа: слово должно встречаться не более чем в 90% документов. (подсказал AI с минимальной и максимальной частотой)\n",
    "all_messages_cleaned = [\" \".join(messages_cleaned_2022),\n",
    "         \" \".join(messages_cleaned_2023),\n",
    "         \" \".join(messages_cleaned_2024),\n",
    "         \" \".join(messages_cleaned_2025)]\n",
    "tfidf = tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, token_pattern=r'\\b[а-яА-Я]{3,}\\b', min_df=2, max_df=0.9 )\n",
    "tfidf = tfidf_vectorizer.fit_transform(all_messages_cleaned)\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b590d54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>аааааа</th>\n",
       "      <th>ааааааа</th>\n",
       "      <th>аааааааа</th>\n",
       "      <th>абакан</th>\n",
       "      <th>абакане</th>\n",
       "      <th>аббревиатурах</th>\n",
       "      <th>аббревиатуру</th>\n",
       "      <th>абзаца</th>\n",
       "      <th>абзаце</th>\n",
       "      <th>абзацев</th>\n",
       "      <th>абонемента</th>\n",
       "      <th>абонементами</th>\n",
       "      <th>абонементе</th>\n",
       "      <th>абонементов</th>\n",
       "      <th>абонементу</th>\n",
       "      <th>абонементы</th>\n",
       "      <th>абонент</th>\n",
       "      <th>абонента</th>\n",
       "      <th>абонентка</th>\n",
       "      <th>абонентки</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.002354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007159</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     аааааа   ааааааа  аааааааа    абакан   абакане  аббревиатурах  \\\n",
       "0  0.005450  0.000000  0.000000  0.000000  0.000000       0.000000   \n",
       "1  0.009530  0.002354  0.000000  0.000000  0.000000       0.002354   \n",
       "2  0.007159  0.002948  0.002948  0.002948  0.002948       0.000000   \n",
       "3  0.000000  0.000000  0.006306  0.006306  0.003153       0.003153   \n",
       "\n",
       "   аббревиатуру    абзаца    абзаце   абзацев  абонемента  абонементами  \\\n",
       "0      0.000000  0.008175  0.000000  0.005450    0.005450      0.000000   \n",
       "1      0.002354  0.000000  0.004709  0.001906    0.003812      0.002354   \n",
       "2      0.000000  0.009546  0.002948  0.000000    0.004773      0.000000   \n",
       "3      0.003153  0.002552  0.000000  0.005105    0.000000      0.003153   \n",
       "\n",
       "   абонементе  абонементов  абонементу  абонементы   абонент  абонента  \\\n",
       "0    0.000000     0.002725    0.006732    0.008175  0.000000  0.000000   \n",
       "1    0.002354     0.007624    0.002354    0.007624  0.007624  0.001906   \n",
       "2    0.002948     0.000000    0.000000    0.000000  0.009546  0.007159   \n",
       "3    0.000000     0.005105    0.000000    0.005105  0.002552  0.005105   \n",
       "\n",
       "   абонентка  абонентки  \n",
       "0   0.000000   0.003366  \n",
       "1   0.002354   0.002354  \n",
       "2   0.002948   0.000000  \n",
       "3   0.000000   0.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#смотрим результат в виде датафрейма, где строки — документы, столбцы — слова, значения — TF‑IDF веса.\n",
    "words = tfidf_vectorizer.get_feature_names_out()\n",
    "import pandas as pd \n",
    "data = tfidf.todense().tolist()\n",
    "result_tfidf = pd.DataFrame(data, columns = words)\n",
    "#выведим первые 20 столбцов, чтобы не перегружать вывод\n",
    "result_tfidf[result_tfidf.columns[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ef9de10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TF-IDF          Word\n",
      "0   0.158049         экспо\n",
      "1   0.117807           пцр\n",
      "2   0.089925      элефанте\n",
      "3   0.084475    знакомимся\n",
      "4   0.065400         ахмад\n",
      "5   0.060586          юань\n",
      "6   0.060586       рыбачук\n",
      "7   0.060586     машинного\n",
      "8   0.057225  рассказываем\n",
      "9   0.057225     лендлорда\n",
      "10  0.054500     юнистрима\n",
      "11  0.054500      кулстори\n",
      "12  0.051775    завтракаем\n",
      "13  0.049050      переписи\n",
      "14  0.049050      пакетики\n",
      "15  0.049050     компонент\n",
      "16  0.049050       вклейку\n",
      "17  0.047123       купчино\n",
      "18  0.047123         англе\n",
      "19  0.043757     экспобанк\n"
     ]
    }
   ],
   "source": [
    "#выведим 20 слов с наибольшим TF-IDF весом для каждого года\n",
    "tfidf2022 = sorted(zip(tfidf.toarray()[0], words), reverse=True)[:20]\n",
    "df_tfidf2022 = pd.DataFrame(tfidf2022, columns=[\"TF-IDF\", \"Word\"])\n",
    "print(df_tfidf2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "160f9970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TF-IDF         Word\n",
      "0   0.171546     выключен\n",
      "1   0.153034        агния\n",
      "2   0.120082        павлы\n",
      "3   0.099116          нко\n",
      "4   0.097209         додо\n",
      "5   0.091491    модерации\n",
      "6   0.085773        павлу\n",
      "7   0.072431    суперверо\n",
      "8   0.062900         веро\n",
      "9   0.057182  потребление\n",
      "10  0.057182   знакомимся\n",
      "11  0.056505        агнии\n",
      "12  0.055276  голосование\n",
      "13  0.053370     зеленило\n",
      "14  0.051464          лир\n",
      "15  0.049558        срачи\n",
      "16  0.049558     площадок\n",
      "17  0.047652     банофбот\n",
      "18  0.047087         чото\n",
      "19  0.045746      вклейку\n"
     ]
    }
   ],
   "source": [
    "tfidf2023=sorted(zip(tfidf.toarray()[1], words), reverse=True)[:20]\n",
    "df_tfidf2023 = pd.DataFrame(tfidf2023, columns=[\"TF-IDF\", \"Word\"])\n",
    "print(df_tfidf2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e596cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TF-IDF            Word\n",
      "0   0.147957        радничка\n",
      "1   0.131252         таланту\n",
      "2   0.126479       отключали\n",
      "3   0.083524            оков\n",
      "4   0.081138        радничке\n",
      "5   0.076365            веро\n",
      "6   0.070744        депревоз\n",
      "7   0.069206        трагедии\n",
      "8   0.069206         протест\n",
      "9   0.066819            июль\n",
      "10  0.064433           напор\n",
      "11  0.059660            скам\n",
      "12  0.059660           дейли\n",
      "13  0.052501             миф\n",
      "14  0.052501           грибы\n",
      "15  0.050111  хахахахахахаха\n",
      "16  0.050111          бойкот\n",
      "17  0.047728     потребление\n",
      "18  0.047728           окове\n",
      "19  0.047728          никита\n"
     ]
    }
   ],
   "source": [
    "tfidf2024 = sorted(zip(tfidf.toarray()[2], words), reverse=True)[:20]\n",
    "df_tfidf2024 = pd.DataFrame(tfidf2024, columns=[\"TF-IDF\", \"Word\"])\n",
    "print(df_tfidf2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "83618d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TF-IDF           Word\n",
      "0   0.114862        таланту\n",
      "1   0.112309            мыш\n",
      "2   0.081973           юнет\n",
      "3   0.081679           скам\n",
      "4   0.078821          боник\n",
      "5   0.075668          бобик\n",
      "6   0.071470        йогурта\n",
      "7   0.069362           кекс\n",
      "8   0.068917           мыша\n",
      "9   0.066365       подписку\n",
      "10  0.066365           кеса\n",
      "11  0.058707            жпт\n",
      "12  0.056751            цой\n",
      "13  0.056751      пейсатель\n",
      "14  0.056155        таланта\n",
      "15  0.051050            гпт\n",
      "16  0.051050          белки\n",
      "17  0.048497  правительства\n",
      "18  0.048497            плс\n",
      "19  0.048497        кальция\n"
     ]
    }
   ],
   "source": [
    "tfidf2025 = sorted(zip(tfidf.toarray()[3], words), reverse=True)[:20]\n",
    "df_tfidf2025 = pd.DataFrame(tfidf2025, columns=[\"TF-IDF\", \"Word\"])\n",
    "print(df_tfidf2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa3793d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TF-IDF          Word\n",
      "0   0.276611       таланту\n",
      "1   0.205852      радничка\n",
      "2   0.187724      выключен\n",
      "3   0.184612    знакомимся\n",
      "4   0.178623     отключали\n",
      "5   0.165541         экспо\n",
      "6   0.163132         агния\n",
      "7   0.160400          скам\n",
      "8   0.159195          додо\n",
      "9   0.158778     суперверо\n",
      "10  0.145275         павлы\n",
      "11  0.144020  рассказываем\n",
      "12  0.143681      кулстори\n",
      "13  0.141884      элефанте\n",
      "14  0.141818          веро\n",
      "15  0.136664    завтракаем\n",
      "16  0.128053           мыш\n",
      "17  0.127882   потребление\n",
      "18  0.123237      радничке\n",
      "19  0.122515           пцр\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TF-IDF по всем документам\n",
    "word_scores = np.asarray(tfidf.sum(axis=0)).flatten()\n",
    "top_words = sorted(zip(word_scores, words), reverse=True)[:20]\n",
    "df_top_words= pd.DataFrame(top_words, columns=[\"TF-IDF\", \"Word\"])\n",
    "print(df_top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c889a08",
   "metadata": {},
   "source": [
    "На четвёртом этапе анализируем коллокации:\n",
    "-извлекаем биграммы для каждого документа\n",
    "-анализируем коллокации с помощью student t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b952e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "from IPython.display import display\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92c993d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#прописываем функцию для получения биграмм из списка слов\n",
    "def ngram_splitter(lst, n):\n",
    "  for i in range(len(lst) - n + 1):\n",
    "    yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a94735d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ребята', 'скиньте'], ['скиньте', 'номер'], ['номер', 'такси'], ['такси', 'срочно'], ['срочно', 'чатика'], ['чатика', 'подающих'], ['подающих', 'визы'], ['визы', 'сербии'], ['сербии', 'кажется'], ['кажется', 'текущих']]\n"
     ]
    }
   ],
   "source": [
    "#проверяем работу функции на биграммах для 2022 года\n",
    "bigrams_2022 = list(ngram_splitter(messages_cleaned_2022, 2))\n",
    "print(bigrams_2022[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f4229",
   "metadata": {},
   "source": [
    "PMI (Pointwise Mutual Information)\n",
    "Смысл: измеряет, насколько вероятность встретить слова вместе выше, чем ожидалось при их независимом появлении.\n",
    "Chi-square (χ²)\n",
    "Смысл: проверяет статистическую значимость связи между словами, сравнивая наблюдаемое распределение с ожидаемым.\n",
    "Likelihood Ratio (LR)\n",
    "Смысл: сравнивает две гипотезы:\n",
    "H₀: слова независимы.\n",
    "H₁: слова связаны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8e695d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#прописываем функцию для получения топ 20 биграм по метрике student_t \n",
    "def bigram_analysis(tokens, top_n=20):\n",
    "    bigrams = list(nltk.ngrams(tokens, 2))\n",
    "    bigram_counts = Counter(bigrams)\n",
    "    counts_df = pd.DataFrame(\n",
    "        [[' '.join(key), key[0], key[1], val] for key, val in bigram_counts.items()],\n",
    "        columns=['bigram', 'word_1', 'word_2', 'count']\n",
    "    ).sort_values(by='count', ascending=False, ignore_index=True)\n",
    "    measures = BigramAssocMeasures()\n",
    "    finder = BigramCollocationFinder.from_words(tokens)\n",
    "    scored = finder.score_ngrams(measures.student_t)\n",
    "    student_df = pd.DataFrame(\n",
    "        [[' '.join([w1, w2]), w1, w2, score] for ((w1, w2), score) in scored],\n",
    "        columns=['bigram', 'word_1', 'word_2', 'student_t']\n",
    "    ).sort_values(by='student_t', ascending=False, ignore_index=True)\n",
    "    \n",
    "    return {\n",
    "        'counts': counts_df.head(top_n),\n",
    "        'student_t': student_df.head(top_n)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e8fe720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# функция для получения топ 20 биграм по метрикам PMI, Chi-square и Likelihood ratio\n",
    "def bigram_analysis(tokens, top_n=20,min_freq=3):\n",
    "    measures = BigramAssocMeasures()\n",
    "    finder = BigramCollocationFinder.from_words(tokens)\n",
    "    finder.apply_freq_filter(min_freq)\n",
    "\n",
    "    # разные метрики\n",
    "    scored_pmi = finder.score_ngrams(measures.pmi)\n",
    "    scored_chi = finder.score_ngrams(measures.chi_sq)\n",
    "    scored_lr = finder.score_ngrams(measures.likelihood_ratio)\n",
    "\n",
    "    # подсчёт частот биграмм\n",
    "    bigram_counts = Counter(zip(tokens[:-1], tokens[1:]))\n",
    "\n",
    "    def to_df(scored, metric_name):\n",
    "        return pd.DataFrame(\n",
    "            [[' '.join([w1, w2]), w1, w2, bigram_counts.get((w1, w2), 0), score]\n",
    "             for ((w1, w2), score) in scored],\n",
    "            columns=['bigram', 'word_1', 'word_2', 'count', metric_name]\n",
    "        ).sort_values(by=metric_name, ascending=False, ignore_index=True).head(top_n)\n",
    "\n",
    "    return {\n",
    "        'PMI': to_df(scored_pmi, 'pmi'),\n",
    "        'Chi-square': to_df(scored_chi, 'chi_sq'),\n",
    "        'Likelihood ratio': to_df(scored_lr, 'lr')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4954035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        bigram         word_1         word_2  count        pmi\n",
      "0                  анице ребац          анице          ребац      3  17.047848\n",
      "1           легализуем учебные     легализуем        учебные      3  17.047848\n",
      "2                     ня кавай             ня          кавай      3  17.047848\n",
      "3             поломками кончно      поломками         кончно      3  17.047848\n",
      "4                 птц телекком            птц       телекком      3  17.047848\n",
      "5   самовольного модерирования   самовольного  модерирования      3  17.047848\n",
      "6           соседях разузнаете        соседях     разузнаете      3  17.047848\n",
      "7                  фиш зелениш            фиш        зелениш      3  17.047848\n",
      "8             веселина маслеше       веселина        маслеше      3  17.047848\n",
      "9         курьерскими службами    курьерскими       службами      4  16.632811\n",
      "10            сараевский чевап     сараевский          чевап      4  16.632811\n",
      "11          плановых внезапных       плановых      внезапных      4  16.632811\n",
      "12        оборудованным клубом  оборудованным         клубом      4  16.632811\n",
      "13         нарядным инвентарем       нарядным     инвентарем      4  16.632811\n",
      "14        накладками геморроем     накладками      геморроем      4  16.632811\n",
      "15         минцифрыв ведомстве      минцифрыв      ведомстве      4  16.632811\n",
      "16          жуткими накладками        жуткими     накладками      4  16.632811\n",
      "17           инвентарем бодрым     инвентарем         бодрым      4  16.632811\n",
      "18                 данила киша         данила           киша      4  16.632811\n",
      "19         гейзерные кофеварки      гейзерные      кофеварки      4  16.632811\n",
      "                   bigram     word_1        word_2  count           lr\n",
      "0            белый картон      белый        картон    226  3122.550541\n",
      "1            крайней мере    крайней          мере    104  1788.226684\n",
      "2              самом деле      самом          деле    100  1549.568674\n",
      "3                 сих пор        сих           пор     62  1104.483200\n",
      "4         ближайшее время  ближайшее         время     78   902.786082\n",
      "5          белого картона     белого       картона     46   805.309232\n",
      "6            любом случае      любом        случае     72   799.204136\n",
      "7           всякий случай     всякий        случай     49   710.461369\n",
      "8            точки зрения      точки        зрения     38   625.244386\n",
      "9            пишите личку     пишите         личку     55   582.470104\n",
      "10            доброго дня    доброго           дня     51   574.649676\n",
      "11                  од од         од            од     36   547.064019\n",
      "12              пару дней       пару          дней     66   542.933086\n",
      "13             друг друга       друг         друга     38   539.143001\n",
      "14         прошу прощения      прошу      прощения     30   520.042999\n",
      "15        последнее время  последнее         время     45   514.741524\n",
      "16            пару недель       пару        недель     44   507.731777\n",
      "17          сколько стоит    сколько         стоит     70   492.884686\n",
      "18               пол года        пол          года     43   455.264835\n",
      "19  бульваре освобождения   бульваре  освобождения     30   448.247696\n",
      "                        bigram         word_1           word_2  count  \\\n",
      "0                     абу даби            абу             даби      7   \n",
      "1         накладками геморроем     накладками        геморроем      4   \n",
      "2                  анице ребац          анице            ребац      3   \n",
      "3                  фиш зелениш            фиш          зелениш      3   \n",
      "4           успехами провалами       успехами        провалами     10   \n",
      "5           соседях разузнаете        соседях       разузнаете      3   \n",
      "6             сараевский чевап     сараевский            чевап      4   \n",
      "7   самовольного модерирования   самовольного    модерирования      3   \n",
      "8                 птц телекком            птц         телекком      3   \n",
      "9             поломками кончно      поломками           кончно      3   \n",
      "10          плановых внезапных       плановых        внезапных      4   \n",
      "11        оборудованным клубом  оборудованным           клубом      4   \n",
      "12                    ня кавай             ня            кавай      3   \n",
      "13         нарядным инвентарем       нарядным       инвентарем      4   \n",
      "14         минцифрыв ведомстве      минцифрыв        ведомстве      4   \n",
      "15                 данила киша         данила             киша      4   \n",
      "16           бодрым кроссфитом         бодрым       кроссфитом      4   \n",
      "17      весами гиперэкстензией         весами  гиперэкстензией      4   \n",
      "18            веселина маслеше       веселина          маслеше      3   \n",
      "19        внезапных отключений      внезапных       отключений      4   \n",
      "\n",
      "      chi_sq  \n",
      "0   406476.0  \n",
      "1   406476.0  \n",
      "2   406476.0  \n",
      "3   406476.0  \n",
      "4   406476.0  \n",
      "5   406476.0  \n",
      "6   406476.0  \n",
      "7   406476.0  \n",
      "8   406476.0  \n",
      "9   406476.0  \n",
      "10  406476.0  \n",
      "11  406476.0  \n",
      "12  406476.0  \n",
      "13  406476.0  \n",
      "14  406476.0  \n",
      "15  406476.0  \n",
      "16  406476.0  \n",
      "17  406476.0  \n",
      "18  406476.0  \n",
      "19  406476.0  \n"
     ]
    }
   ],
   "source": [
    "#результаты скорее просто ради интереса, так как не была проведена лемматизация \n",
    "result_2022 = bigram_analysis(messages_cleaned_2022, top_n=20)\n",
    "print(result_2022['PMI'])\n",
    "print(result_2022['Likelihood ratio'])\n",
    "print(result_2022['Chi-square'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bd23bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      bigram          word_1        word_2  count        pmi\n",
      "0     адаптировалась украшая  адаптировалась       украшая      3  17.532379\n",
      "1                 пруд пруди            пруд         пруди      3  17.532379\n",
      "2                алберт хайн          алберт          хайн      3  17.532379\n",
      "3          ёлочное украшение         ёлочное     украшение      3  17.532379\n",
      "4          экстремист фашист      экстремист        фашист      3  17.532379\n",
      "5       шиномонтаж райончике      шиномонтаж     райончике      3  17.532379\n",
      "6     чрезмерно загрязненный       чрезмерно  загрязненный      3  17.532379\n",
      "7                    хум хау             хум           хау      3  17.532379\n",
      "8            српских сестара         српских       сестара      3  17.532379\n",
      "9    симфоническим оркестром   симфоническим     оркестром      3  17.532379\n",
      "10                свака част           свака          част      3  17.532379\n",
      "11        райончике быстрица       райончике      быстрица      3  17.532379\n",
      "12         радника железнице         радника     железнице      3  17.532379\n",
      "13         холодами выкопать        холодами      выкопать      3  17.532379\n",
      "14     пригодных территориях       пригодных   территориях      3  17.532379\n",
      "15                кета кижуч            кета         кижуч      3  17.532379\n",
      "16         полметра глубиной        полметра      глубиной      3  17.532379\n",
      "17  вопросхороший шиномонтаж   вопросхороший    шиномонтаж      3  17.532379\n",
      "18          градской пивнице        градской       пивнице      3  17.532379\n",
      "19          зеленила заведут        зеленила       заведут      3  17.532379\n",
      "                    bigram        word_1      word_2  count           lr\n",
      "0             белый картон         белый      картон    227  3345.562311\n",
      "1             ночной режим        ночной       режим    154  2376.575688\n",
      "2               самом деле         самом        деле    131  2027.904335\n",
      "3             прошлом году       прошлом        году    143  2006.477770\n",
      "4                  сих пор           сих         пор     96  1690.908596\n",
      "5             крайней мере       крайней        мере     77  1361.132067\n",
      "6           режим выключен         режим    выключен     83  1318.069678\n",
      "7        доступ сообщениям        доступ  сообщениям     63  1100.345535\n",
      "8      сообщениям появится    сообщениям    появится     63  1088.604547\n",
      "9            всякий случай        всякий      случай     74  1085.859633\n",
      "10            любом случае         любом      случае     95  1039.270987\n",
      "11          включен ночной       включен      ночной     63   993.595800\n",
      "12            точки зрения         точки      зрения     61   992.192657\n",
      "13              друг друга          друг       друга     68   966.962936\n",
      "14             доброго дня       доброго         дня     86   960.056114\n",
      "15        различных сферах     различных      сферах     48   923.503569\n",
      "16              павла папа         павла        папа     67   917.432744\n",
      "17  специалистах различных  специалистах   различных     48   910.447508\n",
      "18            режим доступ         режим      доступ     63   901.280126\n",
      "19               пару дней          пару        дней     97   878.438706\n",
      "                     bigram          word_1        word_2  count    chi_sq\n",
      "0                  абу даби             абу          даби      6  568713.0\n",
      "1            увожу кроликов           увожу      кроликов      8  568713.0\n",
      "2         радника железнице         радника     железнице      3  568713.0\n",
      "3        райончике быстрица       райончике      быстрица      3  568713.0\n",
      "4                свака част           свака          част      3  568713.0\n",
      "5   симфоническим оркестром   симфоническим     оркестром      3  568713.0\n",
      "6           српских сестара         српских       сестара      3  568713.0\n",
      "7    традиционном субботнем    традиционном     субботнем      8  568713.0\n",
      "8              хмели сунели           хмели        сунели      7  568713.0\n",
      "9     пригодных территориях       пригодных   территориях      3  568713.0\n",
      "10        холодами выкопать        холодами      выкопать      3  568713.0\n",
      "11                  хум хау             хум           хау      3  568713.0\n",
      "12   чрезмерно загрязненный       чрезмерно  загрязненный      3  568713.0\n",
      "13     шиномонтаж райончике      шиномонтаж     райончике      3  568713.0\n",
      "14        экстремист фашист      экстремист        фашист      3  568713.0\n",
      "15        ёлочное украшение         ёлочное     украшение      3  568713.0\n",
      "16               пруд пруди            пруд         пруди      3  568713.0\n",
      "17   адаптировалась украшая  адаптировалась       украшая      3  568713.0\n",
      "18       поражений зубоввсе       поражений      зубоввсе      6  568713.0\n",
      "19              име презиме             име       презиме      4  568713.0\n"
     ]
    }
   ],
   "source": [
    "result_2023 = bigram_analysis(messages_cleaned_2023, top_n=20)\n",
    "print(result_2023['PMI'])\n",
    "print(result_2023['Likelihood ratio'])\n",
    "print(result_2023['Chi-square'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3dc7c5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        bigram     word_1             word_2  count        pmi\n",
      "0       азиатско тихоокеанский   азиатско      тихоокеанский      3  17.134844\n",
      "1               нижним тагилом     нижним            тагилом      3  17.134844\n",
      "2              царские припасы    царские            припасы      3  17.134844\n",
      "3                  тошин бунар      тошин              бунар      3  17.134844\n",
      "4             раннем пубертате     раннем          пубертате      3  17.134844\n",
      "5         прощение поспешность   прощение        поспешность      3  17.134844\n",
      "6            приношу извинения    приношу          извинения      3  17.134844\n",
      "7   омладине круглосуточныйтел   омладине  круглосуточныйтел      3  17.134844\n",
      "8                обуют ограбят      обуют            ограбят      3  17.134844\n",
      "9                бухты барахты      бухты            барахты      3  17.134844\n",
      "10              лигу чемпионов       лигу          чемпионов      3  17.134844\n",
      "11  качествах профессионализме  качествах   профессионализме      3  17.134844\n",
      "12                заштиту деце    заштиту               деце      3  17.134844\n",
      "13              западного нила  западного               нила      3  17.134844\n",
      "14               деце омладине       деце           омладине      3  17.134844\n",
      "15              высший пилотаж     высший            пилотаж      3  17.134844\n",
      "16                 лазин салаш      лазин              салаш      3  17.134844\n",
      "17                 рога копыта       рога             копыта      3  16.719807\n",
      "18           языкового барьера  языкового            барьера      3  16.719807\n",
      "19                 хитна помоч      хитна              помоч      3  16.719807\n",
      "             bigram     word_1   word_2  count           lr\n",
      "0      белый картон      белый   картон    160  2442.958545\n",
      "1        самом деле      самом     деле    150  2265.204404\n",
      "2           сих пор        сих      пор     96  1625.098028\n",
      "3      крайней мере    крайней     мере     81  1399.342044\n",
      "4      прошлом году    прошлом     году     94  1257.096246\n",
      "5      точки зрения      точки   зрения     56   887.771409\n",
      "6      любом случае      любом   случае     78   875.311032\n",
      "7     всякий случай     всякий   случай     55   810.270889\n",
      "8         пару дней       пару     дней     72   631.673080\n",
      "9         лет назад        лет    назад     75   625.870973\n",
      "10  последнее время  последнее    время     52   595.349236\n",
      "11      краля петра      краля    петра     31   587.729102\n",
      "12       павла папа      павла     папа     35   545.401121\n",
      "13            ха ха         ха       ха     32   541.945586\n",
      "14   несколько дней  несколько     дней     61   496.676645\n",
      "15   золотая корона    золотая   корона     28   478.152662\n",
      "16   белого картона     белого  картона     26   476.774926\n",
      "17   первую очередь     первую  очередь     34   476.184114\n",
      "18    честно говоря     честно   говоря     36   463.709663\n",
      "19  лиманском парке  лиманском    парке     29   462.113925\n",
      "                        bigram      word_1             word_2  count    chi_sq\n",
      "0       азиатско тихоокеанский    азиатско      тихоокеанский      3  431741.0\n",
      "1               лигу чемпионов        лигу          чемпионов      3  431741.0\n",
      "2              царские припасы     царские            припасы      3  431741.0\n",
      "3               увожу кроликов       увожу           кроликов      4  431741.0\n",
      "4                  тошин бунар       тошин              бунар      3  431741.0\n",
      "5               спасён кикнули      спасён            кикнули      6  431741.0\n",
      "6             раннем пубертате      раннем          пубертате      3  431741.0\n",
      "7         прощение поспешность    прощение        поспешность      3  431741.0\n",
      "8            приношу извинения     приношу          извинения      3  431741.0\n",
      "9   омладине круглосуточныйтел    омладине  круглосуточныйтел      3  431741.0\n",
      "10               обуют ограбят       обуют            ограбят      3  431741.0\n",
      "11              нижним тагилом      нижним            тагилом      3  431741.0\n",
      "12               бухты барахты       бухты            барахты      3  431741.0\n",
      "13                 лазин салаш       лазин              салаш      3  431741.0\n",
      "14            доброте душевной     доброте           душевной      5  431741.0\n",
      "15              высший пилотаж      высший            пилотаж      3  431741.0\n",
      "16             генерал адмирал     генерал            адмирал      6  431741.0\n",
      "17               деце омладине        деце           омладине      3  431741.0\n",
      "18  качествах профессионализме   качествах   профессионализме      3  431741.0\n",
      "19       завтракаем знакомимся  завтракаем         знакомимся     18  431741.0\n"
     ]
    }
   ],
   "source": [
    "result_2024 = bigram_analysis(messages_cleaned_2024, top_n=20)\n",
    "print(result_2024['PMI'])\n",
    "print(result_2024['Likelihood ratio'])\n",
    "print(result_2024['Chi-square'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a84cfe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       bigram         word_1        word_2  count        pmi\n",
      "0              амерички кутак       амерички         кутак      3  16.902116\n",
      "1            психиатор натуре      психиатор        натуре      3  16.902116\n",
      "2      финансовой грамотности     финансовой   грамотности      3  16.902116\n",
      "3                  туева хуча          туева          хуча      3  16.902116\n",
      "4        технико пассажирской        технико  пассажирской      3  16.902116\n",
      "5                судски тумач         судски         тумач      3  16.902116\n",
      "6                 рядовой дев        рядовой           дев      3  16.902116\n",
      "7              баним проходим          баним      проходим      3  16.902116\n",
      "8       проведены проводимого      проведены   проводимого      3  16.902116\n",
      "9           вырезано цензурой       вырезано      цензурой      3  16.902116\n",
      "10          бутамирата цитрат     бутамирата        цитрат      3  16.902116\n",
      "11               острой болью         острой         болью      3  16.902116\n",
      "12  долгосрочное планирование   долгосрочное  планирование      3  16.902116\n",
      "13         лекарственных трав  лекарственных          трав      3  16.902116\n",
      "14    антипригарным покрытием  антипригарным     покрытием      3  16.487078\n",
      "15                марш бросок           марш        бросок      3  16.487078\n",
      "16                 яша томиче            яша        томиче      3  16.487078\n",
      "17             хаджи рувимова          хаджи      рувимова      4  16.487078\n",
      "18                уцхо сунели           уцхо        сунели      3  16.487078\n",
      "19               сайлент хилл        сайлент          хилл      3  16.487078\n",
      "             bigram     word_1    word_2  count           lr\n",
      "0           сих пор        сих       пор     90  1520.882693\n",
      "1        самом деле      самом      деле     96  1457.511230\n",
      "2      белый картон      белый    картон     77  1189.036332\n",
      "3      крайней мере    крайней      мере     60  1001.194525\n",
      "4      любом случае      любом    случае     87   995.688287\n",
      "5        павла папа      павла      папа     44   763.993185\n",
      "6               з ы          з         ы     41   676.289475\n",
      "7      прошлом году    прошлом      году     44   610.183418\n",
      "8        друг друга       друг     друга     41   583.894744\n",
      "9      точки зрения      точки    зрения     34   532.433402\n",
      "10      краля петра      краля     петра     28   518.412300\n",
      "11  последнее время  последнее     время     43   483.739174\n",
      "12            ха ха         ха        ха     31   474.484466\n",
      "13        лет назад        лет     назад     60   466.320128\n",
      "14  цыганская почта  цыганская     почта     25   438.521906\n",
      "15    данном случае     данном    случае     34   417.790325\n",
      "16   белого картона     белого   картона     22   411.150897\n",
      "17    каким образом      каким   образом     29   401.909560\n",
      "18   прошу прощения      прошу  прощения     23   396.721078\n",
      "19    всякий случай     всякий    случай     28   394.776964\n",
      "                       bigram         word_1        word_2  count    chi_sq\n",
      "0            альберт эйнштейн        альберт      эйнштейн      5  367422.0\n",
      "1       проведены проводимого      проведены   проводимого      3  367422.0\n",
      "2              хаджи рувимова          хаджи      рувимова      4  367422.0\n",
      "3      финансовой грамотности     финансовой   грамотности      3  367422.0\n",
      "4                  туева хуча          туева          хуча      3  367422.0\n",
      "5        технико пассажирской        технико  пассажирской      3  367422.0\n",
      "6                судски тумач         судски         тумач      3  367422.0\n",
      "7              свинской масти       свинской         масти      5  367422.0\n",
      "8                 рядовой дев        рядовой           дев      3  367422.0\n",
      "9           религиями сектами      религиями       сектами      4  367422.0\n",
      "10           психиатор натуре      психиатор        натуре      3  367422.0\n",
      "11             амерички кутак       амерички         кутак      3  367422.0\n",
      "12      пояснительную бригаду  пояснительную       бригаду      6  367422.0\n",
      "13          вырезано цензурой       вырезано      цензурой      3  367422.0\n",
      "14               острой болью         острой         болью      3  367422.0\n",
      "15          бутамирата цитрат     бутамирата        цитрат      3  367422.0\n",
      "16      вступительных взносов  вступительных       взносов      4  367422.0\n",
      "17             баним проходим          баним      проходим      3  367422.0\n",
      "18  долгосрочное планирование   долгосрочное  планирование      3  367422.0\n",
      "19             здравых хранах        здравых        хранах      4  367422.0\n"
     ]
    }
   ],
   "source": [
    "result_2025 = bigram_analysis(messages_cleaned_2025, top_n=20)\n",
    "print(result_2025['PMI'])\n",
    "print(result_2025['Likelihood ratio'])\n",
    "print(result_2025['Chi-square'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24cf6cc",
   "metadata": {},
   "source": [
    "На пятом этапе создаём Telegram-бота, чтобы показать, как данный корпус можно использовать дальше:\n",
    "Telegram-бот выводит сообщения из всего корпуса текстов по заданному слову"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f64e4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "from telebot import types\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gde_kupit_tvorog_bot = #токен# \n",
    "bot = telebot.TeleBot(gde_kupit_tvorog_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ebb6c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages = all_messages_2022 + all_messages_2023 + all_messages_2024 + all_messages_2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2eac93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#логика выдачи следующих 5 сообщений с конца была сделана с помощью copilot \n",
    "user_sessions = {}\n",
    "\n",
    "@bot.message_handler(commands=[\"start\"])\n",
    "def start(message, res=False):\n",
    "    bot.send_message(message.chat.id,\n",
    "        \"Добрый день!\\n\"\n",
    "        \"Просто напишите слово кириллицей — и я выведу все сообщения из базы, где оно встречается. Например \\\"творог\\\".\")\n",
    "\n",
    "@bot.message_handler(content_types=[\"text\"])\n",
    "def search_word(message):\n",
    "    word = message.text.strip().lower() #если уберем lower, то можем вводить словосочетания, но есть нюанс \n",
    "\n",
    "    # если пользователь нажал кнопку \"Да, пришли\"\n",
    "    if word == \"да, пришли\" and message.chat.id in user_sessions:\n",
    "        session = user_sessions[message.chat.id]\n",
    "\n",
    "        # сначала уменьшаем индекс\n",
    "        session[\"index\"] -= 5\n",
    "        start = max(0, session[\"index\"])\n",
    "        end = start + 5\n",
    "\n",
    "        next_batch = session[\"results\"][start:end]\n",
    "\n",
    "        for w in next_batch:\n",
    "            bot.send_message(message.chat.id, f\"📌 {w}\")\n",
    "            time.sleep(1)\n",
    "\n",
    "        if session[\"index\"] > 0:\n",
    "            markup = types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "            item1 = types.KeyboardButton(\"Да, пришли\")\n",
    "            item2 = types.KeyboardButton(\"Нет, достаточно\")\n",
    "            markup.row(item1, item2)\n",
    "            bot.send_message(message.chat.id, \"Хотите ещё 5 предыдущих сообщений?\", reply_markup=markup)\n",
    "        else:\n",
    "            bot.send_message(message.chat.id, \"Все сообщения показаны.\", reply_markup=types.ReplyKeyboardRemove())\n",
    "        return\n",
    "\n",
    "    if word == \"нет, достаточно\":\n",
    "        bot.send_message(message.chat.id, \"Окей, остановились 👍\", reply_markup=types.ReplyKeyboardRemove())\n",
    "        user_sessions.pop(message.chat.id, None)\n",
    "        return\n",
    "\n",
    "    # обычный поиск\n",
    "    result = [w for w in all_messages if word in w.lower().split()]\n",
    "    if not result:\n",
    "        bot.send_message(message.chat.id, \"Совпадений не найдено.\")\n",
    "        return\n",
    "\n",
    "    # сохраняем результаты: начинаем с конца\n",
    "    user_sessions[message.chat.id] = {\"results\": result, \"index\": len(result)}\n",
    "\n",
    "    # показываем последние 5\n",
    "    last_batch = result[-5:]\n",
    "    for w in last_batch:\n",
    "        bot.send_message(message.chat.id, f\"📌 {w}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    user_sessions[message.chat.id][\"index\"] = len(result) - 5\n",
    "    \n",
    "    if len(result) > 5:\n",
    "        bot.send_message(message.chat.id, f\"👉 Найдено {len(result)} сообщений. Показаны последние 5.\")\n",
    "        markup = types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "        item1 = types.KeyboardButton(\"Да, пришли\")\n",
    "        item2 = types.KeyboardButton(\"Нет, достаточно\")\n",
    "        markup.row(item1, item2)\n",
    "        bot.send_message(message.chat.id, \"Хотите посмотреть еще 5 предыдущих сообщений?\", reply_markup=markup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62d919cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.polling(none_stop=True, interval=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
